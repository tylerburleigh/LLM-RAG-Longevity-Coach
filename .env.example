# LLM-RAG-Longevity-Coach Environment Variables
# Copy this file to .env and fill in your actual values

# =============================================================================
# Required API Keys
# =============================================================================

# OpenAI API Key (required for OpenAI models like o3, o4-mini)
OPENAI_API_KEY=your_openai_api_key_here

# Google API Key (optional, required only for Gemini models)
GEMINI_API_KEY=your_GEMINI_API_KEY_here

# =============================================================================
# OAuth2 Configuration (required for authentication)
# =============================================================================

# Google OAuth2 Client ID (get from Google Cloud Console)
GOOGLE_CLIENT_ID=your_google_client_id_here

# Google OAuth2 Client Secret (get from Google Cloud Console)
GOOGLE_CLIENT_SECRET=your_google_client_secret_here

# OAuth2 Redirect URI (use localhost for local development)
# For local development: http://localhost:8501/
# For production: https://yourdomain.com/
OAUTH_REDIRECT_URI=http://localhost:8501/

# Session timeout in hours (default: 24)
SESSION_TIMEOUT_HOURS=24

# Enable insecure transport for OAuth2 development (default: true)
# Set to false in production with HTTPS
OAUTH_INSECURE_TRANSPORT=true

# =============================================================================
# Vector Store Configuration (optional)
# =============================================================================

# Directory for vector store data (default: vector_store_data)
VECTOR_STORE_FOLDER=vector_store_data

# FAISS index filename (default: faiss_index.bin)
FAISS_INDEX_FILENAME=faiss_index.bin

# Documents filename (default: documents.pkl)
DOCUMENTS_FILENAME=documents.pkl

# =============================================================================
# LLM Configuration (optional)
# =============================================================================

# Default LLM model (default: o3)
# Supported models: o3, o4-mini, gemini-2.5-pro
DEFAULT_LLM_MODEL=o3

# Default temperature for LLM responses (default: 1.0)
DEFAULT_TEMPERATURE=1.0

# =============================================================================
# Embedding Configuration (optional)
# =============================================================================

# Embedding model (default: text-embedding-3-large)
EMBEDDING_MODEL=text-embedding-3-large

# Embedding dimension (default: 3072)
EMBEDDING_DIMENSION=3072

# =============================================================================
# Search Configuration (optional)
# =============================================================================

# Default top-k results (default: 5)
DEFAULT_TOP_K=5

# RRF K parameter for rank fusion (default: 60)
RRF_K=60

# Search multiplier for fetching more results before RRF (default: 2)
SEARCH_MULTIPLIER=2

# =============================================================================
# Document Processing (optional)
# =============================================================================

# Documents file path (default: docs.jsonl)
DOCS_FILE=docs.jsonl

# Maximum document length (default: 10000)
MAX_DOCUMENT_LENGTH=10000

# =============================================================================
# Feature Flags (optional)
# =============================================================================

# Enable LangChain chains (default: false)
USE_LANGCHAIN_CHAINS=false

# =============================================================================
# Logging Configuration (optional)
# =============================================================================

# Log level (default: INFO)
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# =============================================================================
# Insight Generation (optional)
# =============================================================================

# Maximum number of insights to generate (default: 5)
MAX_INSIGHTS=5

# Maximum number of clarifying questions (default: 3)
MAX_CLARIFYING_QUESTIONS=3

# =============================================================================
# Cache Configuration (optional)
# =============================================================================

# Cache TTL in seconds (default: 3600 = 1 hour)
CACHE_TTL_SECONDS=3600

# =============================================================================
# Multi-Tenant Configuration (optional)
# =============================================================================

# Root directory for user data (default: user_data)
USER_DATA_ROOT=user_data

# Vector store cache size (default: 5)
VECTOR_STORE_CACHE_SIZE=5

# =============================================================================
# Cloud Storage Configuration (optional)
# =============================================================================

# Storage backend (default: local)
# Options: local, gcp
STORAGE_BACKEND=local

# GCP Project ID (required if using GCP storage)
GCP_PROJECT_ID=your_gcp_project_id

# GCP Bucket Name (required if using GCP storage)
GCP_BUCKET_NAME=longevity-coach-data

# GCP Credentials Path (optional, uses Application Default Credentials if not set)
# GCP_CREDENTIALS_PATH=/path/to/service-account.json

# =============================================================================
# Encryption Configuration (optional)
# =============================================================================

# Enable encryption (default: true)
ENABLE_ENCRYPTION=true

# Encryption algorithm (default: AES-GCM)
ENCRYPTION_ALGORITHM=AES-GCM

# =============================================================================
# Setup Instructions
# =============================================================================

# 1. Copy this file to .env: cp .env.example .env
# 2. Fill in your API keys and OAuth credentials
# 3. Customize other settings as needed
# 4. Run the application: streamlit run app.py

# For OAuth2 setup:
# 1. Go to Google Cloud Console
# 2. Create a new project or select existing
# 3. Enable Google+ API
# 4. Create OAuth2 credentials
# 5. Add your redirect URI (http://localhost:8501/)
# 6. Copy Client ID and Client Secret to this file